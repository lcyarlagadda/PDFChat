{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11Tb7F8_lfwq",
        "outputId": "884f7652-12f0-4a49-d9c3-d91816b9f531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m143.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m146.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2, pyngrok, pydeck, streamlit\n",
            "Successfully installed PyPDF2-3.0.1 pydeck-0.9.1 pyngrok-7.4.1 streamlit-1.50.0\n"
          ]
        }
      ],
      "source": [
        "%pip install streamlit PyPDF2 transformers accelerate pyngrok python-dotenv torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hugging Face Token Setup\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Get Hugging Face token\n",
        "hf_token = getpass(\"Enter your Hugging Face token: \")\n",
        "\n",
        "# Set the token as environment variable\n",
        "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = hf_token\n",
        "\n",
        "print(\"✅ Hugging Face token set successfully!\")\n",
        "print(\"🔑 Token will be used for model authentication\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf9dbp3vqJ56",
        "outputId": "4b44b73d-f06c-41da-e136-bec203a97697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Get ngrok token from environment variable\n",
        "NGROK_AUTH_TOKEN = os.getenv(\"NGROK_AUTH_TOKEN\")\n",
        "\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    # Register the token\n",
        "    !ngrok authtoken $NGROK_AUTH_TOKEN\n",
        "    print(\"Ngrok token loaded from environment\")\n",
        "else:\n",
        "    print(\" NGROK_AUTH_TOKEN not found in .env file\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from PyPDF2 import PdfReader\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "st.set_page_config(page_title=\"PDF Chat\", page_icon=\"📄\", layout=\"wide\")\n",
        "\n",
        "# Clean CSS styling\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        "    /* Hide Streamlit header */\n",
        "    header[data-testid=\"stHeader\"] {\n",
        "        display: none;\n",
        "    }\n",
        "    \n",
        "    .stApp > div:first-child {\n",
        "        padding-top: 0;\n",
        "    }\n",
        "    \n",
        "    /* Main container */\n",
        "    .main-container {\n",
        "        max-width: 800px;\n",
        "        margin: 0 auto;\n",
        "        padding: 20px;\n",
        "        padding-bottom: 100px;\n",
        "    }\n",
        "    \n",
        "    /* Header */\n",
        "    .header {\n",
        "        text-align: center;\n",
        "        color: #ffffff;\n",
        "        font-size: 24px;\n",
        "        font-weight: 600;\n",
        "        margin-bottom: 20px;\n",
        "    }\n",
        "    \n",
        "    /* Chat area - no container */\n",
        "    .chat-area {\n",
        "        padding: 20px;\n",
        "        margin-bottom: 20px;\n",
        "    }\n",
        "    \n",
        "    /* Message styling */\n",
        "    .message {\n",
        "        margin-bottom: 15px;\n",
        "        display: flex;\n",
        "    }\n",
        "    \n",
        "    .message.user {\n",
        "        justify-content: flex-end;\n",
        "    }\n",
        "    \n",
        "    .message.bot {\n",
        "        justify-content: flex-start;\n",
        "    }\n",
        "    \n",
        "    .message-content {\n",
        "        max-width: 70%;\n",
        "        padding: 12px 16px;\n",
        "        border-radius: 18px;\n",
        "        font-size: 14px;\n",
        "        line-height: 1.4;\n",
        "        word-wrap: break-word;\n",
        "    }\n",
        "    \n",
        "    .message.user .message-content {\n",
        "        background: #007bff;\n",
        "        color: white;\n",
        "        border-bottom-right-radius: 4px;\n",
        "    }\n",
        "    \n",
        "    .message.bot .message-content {\n",
        "        background: #f8f9fa;\n",
        "        color: #333;\n",
        "        border: 1px solid #e9ecef;\n",
        "        border-bottom-left-radius: 4px;\n",
        "    }\n",
        "    \n",
        "    /* Typing indicator */\n",
        "    .typing {\n",
        "        background: #f8f9fa;\n",
        "        color: #6c757d;\n",
        "        padding: 12px 16px;\n",
        "        border-radius: 18px;\n",
        "        border-bottom-left-radius: 4px;\n",
        "        font-style: italic;\n",
        "        max-width: 70%;\n",
        "        border: 1px solid #e9ecef;\n",
        "        animation: pulse 1.5s infinite;\n",
        "    }\n",
        "    \n",
        "    @keyframes pulse {\n",
        "        0%, 100% { opacity: 0.6; }\n",
        "        50% { opacity: 1; }\n",
        "    }\n",
        "    \n",
        "    /* Input area - fixed at bottom */\n",
        "    .input-area {\n",
        "        position: fixed;\n",
        "        bottom: 0;\n",
        "        left: 0;\n",
        "        right: 0;\n",
        "        background: #000000;\n",
        "        padding: 15px;\n",
        "        box-shadow: 0 -2px 4px rgba(0,0,0,0.3);\n",
        "        z-index: 1000;\n",
        "    }\n",
        "    \n",
        "    /* Input field */\n",
        "    .stTextInput > div > div > input {\n",
        "        padding: 12px 20px;\n",
        "        font-size: 14px;\n",
        "        background: #333333;\n",
        "        color: #ffffff;\n",
        "        height: 48px;\n",
        "        transition: border-color 0.15s ease-in-out;\n",
        "    }\n",
        "    \n",
        "    .stTextInput > div > div > input:focus {\n",
        "        border-color: #ffffff;\n",
        "        box-shadow: 0 0 0 0.2rem rgba(255,255,255,0.25);\n",
        "        outline: none;\n",
        "    }\n",
        "    \n",
        "    .stTextInput > div > div > input::placeholder {\n",
        "        color: #cccccc;\n",
        "    }\n",
        "    \n",
        "    .stTextInput {\n",
        "        width: 100%;\n",
        "    }\n",
        "    \n",
        "    .stApp {\n",
        "        background: #000000;\n",
        "    }\n",
        "    \n",
        "    .stSuccess {\n",
        "        background: #d4edda;\n",
        "        border: 1px solid #c3e6cb;\n",
        "        color: #155724;\n",
        "        border-radius: 8px;\n",
        "        padding: 12px;\n",
        "        margin-bottom: 20px;\n",
        "    }\n",
        "    \n",
        "    .stInfo {\n",
        "        background: #d1ecf1;\n",
        "        border: 1px solid #bee5eb;\n",
        "        color: #0c5460;\n",
        "        border-radius: 8px;\n",
        "        padding: 12px;\n",
        "        margin-bottom: 10px;\n",
        "    }\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "# Main app\n",
        "st.markdown('<div class=\"main-container\">', unsafe_allow_html=True)\n",
        "st.markdown('<div class=\"header\">📄PDF Chat</div>', unsafe_allow_html=True)\n",
        "\n",
        "# Load model - Using Mistral for better performance\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    nlp = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
        "        device=0 if torch.cuda.is_available() else -1,\n",
        "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
        "        trust_remote_code=True,\n",
        "        use_auth_token=True  # Use the HF token for authentication\n",
        "    )\n",
        "    return nlp\n",
        "\n",
        "nlp = load_model()\n",
        "\n",
        "# Upload multiple PDFs\n",
        "uploaded_files = st.file_uploader(\"Upload PDF files\", type=\"pdf\", accept_multiple_files=True)\n",
        "\n",
        "if uploaded_files:\n",
        "    # Process all uploaded files into a single unified document\n",
        "    all_pdf_text = \"\"\n",
        "    file_info = []\n",
        "    total_pages = 0\n",
        "    \n",
        "    # Process each file and combine into unified document\n",
        "    for uploaded_file in uploaded_files:\n",
        "        reader = PdfReader(uploaded_file)\n",
        "        file_text = \"\".join([page.extract_text() or \"\" for page in reader.pages])\n",
        "        total_pages += len(reader.pages)\n",
        "        \n",
        "        # Add file content to unified document with minimal separation\n",
        "        all_pdf_text += f\" {file_text}\"\n",
        "        file_info.append(f\"{uploaded_file.name}: {len(file_text)} characters, {len(reader.pages)} pages\")\n",
        "    \n",
        "    # Display unified document information\n",
        "    st.success(f\"{len(uploaded_files)} PDF(s) processed, {len(all_pdf_text)} characters!\")\n",
        "    for info in file_info:\n",
        "        st.info(info)\n",
        "    \n",
        "    # Store unified text as single document\n",
        "    pdf_text = all_pdf_text\n",
        "\n",
        "    # Initialize conversation\n",
        "    if \"conversation\" not in st.session_state:\n",
        "        st.session_state.conversation = []\n",
        "    \n",
        "    if \"processing\" not in st.session_state:\n",
        "        st.session_state.processing = False\n",
        "\n",
        "    # Chat area - no container\n",
        "    st.markdown('<div class=\"chat-area\">', unsafe_allow_html=True)\n",
        "    \n",
        "    # Display messages\n",
        "    for turn in st.session_state.conversation:\n",
        "        if turn[\"role\"] == \"user\":\n",
        "            st.markdown(f'''\n",
        "                <div class=\"message user\">\n",
        "                    <div class=\"message-content\">{turn[\"text\"]}</div>\n",
        "                </div>\n",
        "            ''', unsafe_allow_html=True)\n",
        "        else:\n",
        "            st.markdown(f'''\n",
        "                <div class=\"message bot\">\n",
        "                    <div class=\"message-content\">{turn[\"text\"]}</div>\n",
        "                </div>\n",
        "            ''', unsafe_allow_html=True)\n",
        "    \n",
        "    # Show typing indicator\n",
        "    if st.session_state.processing:\n",
        "        st.markdown('<div class=\"typing\"> Bot is thinking...</div>', unsafe_allow_html=True)\n",
        "    \n",
        "    st.markdown('</div>', unsafe_allow_html=True)\n",
        "    \n",
        "    # Input area\n",
        "    st.markdown('<div class=\"input-area\">', unsafe_allow_html=True)\n",
        "    \n",
        "    # Use dynamic key to clear input field\n",
        "    if \"input_key\" not in st.session_state:\n",
        "        st.session_state.input_key = 0\n",
        "    \n",
        "    # Reset key when input is cleared\n",
        "    if st.session_state.get(\"input_cleared\", False):\n",
        "        st.session_state.input_key += 1\n",
        "        st.session_state.input_cleared = False\n",
        "    \n",
        "    user_input = st.text_input(\"\", placeholder=\"Type your message here...\", key=f\"user_input_{st.session_state.input_key}\", disabled=st.session_state.processing)\n",
        "    st.markdown('</div>', unsafe_allow_html=True)\n",
        "\n",
        "    # Handle input submission - only when user types and presses Enter\n",
        "    if user_input and not st.session_state.processing:\n",
        "        # Check if this is a new message (not already processed)\n",
        "        if \"last_input\" not in st.session_state or st.session_state.last_input != user_input:\n",
        "            st.session_state.conversation.append({\"role\": \"user\", \"text\": user_input})\n",
        "            st.session_state.processing = True\n",
        "            st.session_state.last_input = user_input\n",
        "            # Clear the input field by using a different key\n",
        "            st.session_state.input_cleared = True\n",
        "            st.rerun()\n",
        "    \n",
        "    # Process bot response\n",
        "    if st.session_state.processing and len(st.session_state.conversation) > 0 and st.session_state.conversation[-1][\"role\"] == \"user\":\n",
        "        # Enhanced prompt engineering for better, more grounded answers\n",
        "        user_question = st.session_state.conversation[-1]['text']\n",
        "        \n",
        "        # Build conversation context\n",
        "        conversation_context = \"\"\n",
        "        for i, turn in enumerate(st.session_state.conversation[:-1]):\n",
        "            if turn[\"role\"] == \"user\":\n",
        "                conversation_context += f\"Previous Question: {turn['text']}\\n\"\n",
        "            else:\n",
        "                conversation_context += f\"Previous Answer: {turn['text']}\\n\"\n",
        "        \n",
        "        # Advanced prompt with multiple techniques\n",
        "        prompt = f\"\"\"<s>[INST] You are an expert AI assistant specialized in analyzing and answering questions about PDF documents. Your task is to provide accurate, comprehensive, and well-structured answers based solely on the document content provided.\n",
        "\n",
        "DOCUMENT CONTENT:\n",
        "{pdf_text[:4000]}\n",
        "\n",
        "CONVERSATION HISTORY:\n",
        "{conversation_context}\n",
        "\n",
        "CURRENT QUESTION: {user_question}\n",
        "\n",
        "INSTRUCTIONS:\n",
        "1. Analyze the document content carefully to find relevant information\n",
        "2. Provide a comprehensive answer based on the document\n",
        "3. Structure your answer clearly with key points\n",
        "4. If the user asks for summary, summarize the document, if the user asks for a specific question, answer it.\n",
        "5. Quote relevant sections from the document when appropriate\n",
        "6. Be precise and avoid speculation\n",
        "7. Only when there is no related information in the document, say \"Based on the document, I cannot find specific information about this topic\"\n",
        "\n",
        "Please provide your answer: [/INST]\"\"\"\n",
        "\n",
        "        # Generate bot response with enhanced parameters\n",
        "        response = nlp(prompt, max_length=512, do_sample=True, temperature=0.2, top_p=0.85, repetition_penalty=1.1, pad_token_id=nlp.tokenizer.eos_token_id)\n",
        "        answer = response[0][\"generated_text\"]\n",
        "        \n",
        "        # Extract only the answer part (remove the prompt and instruction tags)\n",
        "        if \"[/INST]\" in answer:\n",
        "            answer = answer.split(\"[/INST]\")[-1].strip()\n",
        "        # Remove any remaining instruction tags\n",
        "        answer = answer.replace(\"<s>\", \"\").replace(\"</s>\", \"\").strip()\n",
        "        \n",
        "        st.session_state.conversation.append({\"role\": \"bot\", \"text\": answer})\n",
        "        st.session_state.processing = False\n",
        "        st.rerun()\n",
        "\n",
        "st.markdown('</div>', unsafe_allow_html=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "# Kill any existing ngrok processes\n",
        "ngrok.kill()\n",
        "\n",
        "# Kill any existing Streamlit processes\n",
        "try:\n",
        "    os.system(\"pkill -f streamlit\")\n",
        "    time.sleep(2)\n",
        "except:\n",
        "    pass\n",
        "\n",
        "# Start Streamlit in the background\n",
        "subprocess.Popen([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"])\n",
        "\n",
        "# Wait a few seconds for Streamlit to start\n",
        "time.sleep(5)\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"🌐 Streamlit URL:\", public_url)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
